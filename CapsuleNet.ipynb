{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled18.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP6YvFdYonoLdoTncQ3Vh5Z"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YI8icSwfLh5f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "27b3ae07-fe4d-4984-c5e3-4422edab9ae7"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import keras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBB029hSLbP7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import cifar100\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfDydjUkplMp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_label_classes = 100\n",
        "input_image_shape = [32,32,3]\n",
        "batch_size = 32\n",
        "dim_capsule = 16\n",
        "num_routings = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h13TQ1_7MP7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.keras.layers.Input(shape=input_image_shape, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGkSq2VsNMKq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv1 = tf.keras.layers.Conv2D(filters=256, kernel_size=9, strides=1, padding='valid', activation='relu', name='conv1')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTSJ5DomN5kT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "primary_capsule = tf.keras.layers.Conv2D(filters=256, kernel_size=9, strides=2, padding = 'valid', name='primarycap_conv2d')(conv1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvGxnP2bOTmv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "primary_capsule = tf.keras.layers.Reshape(target_shape=[-1, 8], name='primarycap_reshape')(primary_capsule)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQJMTsNyP0co",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def squash(vectors, axis=-1):\n",
        " \n",
        "    s_squared_norm = tf.reduce_sum(tf.square(vectors), axis, keepdims=True)\n",
        "    scale = s_squared_norm / (1 + s_squared_norm) / tf.sqrt(s_squared_norm + 0.000000000000000000001)\n",
        "    return scale * vectors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJOSqIH9Oqu6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "primary_capsule_output = tf.keras.layers.Lambda(squash, name='primarycap_squash')(primary_capsule)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3lvivJStDgr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "db880a17-7ac0-42c4-f7b6-84c322366eac"
      },
      "source": [
        "primary_capsule_output.shape[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2048"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73gkOV_douuh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Z = tf.keras.layers.Layer()\n",
        "W = Z.add_weight(shape=[num_label_classes, primary_capsule_output.shape[1], dim_capsule, primary_capsule_output.shape[2]], initializer=tf.keras.initializers.GlorotUniform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOItVQ_FK97P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "primary_capsule_output_expanded = tf.expand_dims(tf.expand_dims(primary_capsule_output, 1), -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHUOzalMLF0-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "primary_capsule_output_tiled = tf.tile(primary_capsule_output_expanded, [1, num_label_classes, 1, 1, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWpx90UWLXQN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "primary_capsule_output_hat = tf.squeeze(tf.map_fn(lambda x: tf.matmul(W, x), elems=primary_capsule_output_tiled))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Wuwv8mtN8VT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b = tf.zeros(shape=[primary_capsule_output.shape[0], num_label_classes, 1, primary_capsule_output.shape[1]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGZTp8AIOU-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(num_routings):\n",
        "            c = tf.nn.softmax(b, axis=1)\n",
        "            outputs = squash(tf.matmul(c, primary_capsule_output_hat))\n",
        "\n",
        "            if i < num_routings - 1:\n",
        "                b = b + tf.matmul(outputs, primary_capsule_output_hat, transpose_b=True)\n",
        "\n",
        "digit_caps = tf.squeeze(outputs, name='digitcaps')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fy-3U8K16ib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Length(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Compute the length of vectors. This is used to compute a Tensor that has the same shape with y_true in margin_loss.\n",
        "    Using this layer as model's output can directly predict labels by using `y_pred = np.argmax(model.predict(x), 1)`\n",
        "    inputs: shape=[None, num_vectors, dim_vector]\n",
        "    output: shape=[None, num_vectors]\n",
        "    \"\"\"\n",
        "    def call(self, inputs, **kwargs):\n",
        "        return tf.sqrt(tf.reduce_sum(tf.square(inputs), -1) + 0.0000000000001)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[:-1]\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(Length, self).get_config()\n",
        "        return config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYVKHc5E2CMS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out_caps = Length(name='capsnet')(digit_caps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXVaxwVCTB2L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#out_caps = tf.sqrt(tf.reduce_sum(tf.square(digit_caps), -1) + 0.0000000000001, name = 'capsnet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZEYnUsmqFgb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "90a7ced5-944a-4970-eb1b-c8ca63400222"
      },
      "source": [
        "out_caps.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([32, 100])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h__tmQg3gVNA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = tf.keras.layers.Input(shape=(num_label_classes,))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9FCypjqsY8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.keras.backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmL2HTUPLUUv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Mask(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Mask a Tensor with shape=[None, num_capsule, dim_vector] either by the capsule with max length or by an additional \n",
        "    input mask. Except the max-length capsule (or specified capsule), all vectors are masked to zeros. Then flatten the\n",
        "    masked Tensor.\n",
        "    For example:\n",
        "        ```\n",
        "        x = keras.layers.Input(shape=[8, 3, 2])  # batch_size=8, each sample contains 3 capsules with dim_vector=2\n",
        "        y = keras.layers.Input(shape=[8, 3])  # True labels. 8 samples, 3 classes, one-hot coding.\n",
        "        out = Mask()(x)  # out.shape=[8, 6]\n",
        "        # or\n",
        "        out2 = Mask()([x, y])  # out2.shape=[8,6]. Masked with true labels y. Of course y can also be manipulated.\n",
        "        ```\n",
        "    \"\"\"\n",
        "    def call(self, inputs, **kwargs):\n",
        "        if type(inputs) is list:  # true label is provided with shape = [None, n_classes], i.e. one-hot code.\n",
        "            assert len(inputs) == 2\n",
        "            inputs, mask = inputs\n",
        "        else:  # if no true label, mask by the max length of capsules. Mainly used for prediction\n",
        "            # compute lengths of capsules\n",
        "            x = tf.sqrt(tf.reduce_sum(tf.square(inputs), -1))\n",
        "            # generate the mask which is a one-hot code.\n",
        "            # mask.shape=[None, n_classes]=[None, num_capsule]\n",
        "            mask = tf.one_hot(indices=tf.argmax(x, 1), depth=x.shape[1])\n",
        "\n",
        "        # inputs.shape=[None, num_capsule, dim_capsule]\n",
        "        # mask.shape=[None, num_capsule]\n",
        "        # masked.shape=[None, num_capsule * dim_capsule]\n",
        "        masked = K.batch_flatten(inputs * tf.expand_dims(mask, -1))\n",
        "        return masked\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if type(input_shape[0]) is tuple:  # true label provided\n",
        "            return tuple([None, input_shape[0][1] * input_shape[0][2]])\n",
        "        else:  # no true label provided\n",
        "            return tuple([None, input_shape[1] * input_shape[2]])\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(Mask, self).get_config()\n",
        "        return config\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vE_VSbiwLIVx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Decoder network.\n",
        "masked_by_y = Mask()([digit_caps, y])  # The true label is used to mask the output of capsule layer. For training\n",
        "masked = Mask()(digit_caps)  # Mask using the capsule with maximal length. For prediction\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ctpQ1gWpBg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#masked_by_y = K.batch_flatten(digit_caps * tf.expand_dims(y, -1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dULcACzDhSlI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#z = tf.sqrt(tf.reduce_sum(tf.square(digit_caps), -1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsMo6v7ouBF0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#mask = tf.one_hot(indices=tf.argmax(z, 1), depth=z.shape[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcR7xlb9hVni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#masked = K.batch_flatten(digit_caps * tf.expand_dims(mask, -1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkJLNHjco-Fs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder = tf.keras.models.Sequential(name='decoder')\n",
        "decoder.add(tf.keras.layers.Dense(512, activation='relu', input_dim=16 * num_label_classes))\n",
        "decoder.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
        "decoder.add(tf.keras.layers.Dense(np.prod(input_image_shape), activation='sigmoid'))\n",
        "decoder.add(tf.keras.layers.Reshape(target_shape=input_image_shape, name='out_recon'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gxkIlQThxeU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_model = tf.keras.models.Model([x, y], [out_caps, decoder(masked_by_y)])\n",
        "eval_model = tf.keras.models.Model(x, [out_caps, decoder(masked)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxbMcYApnUot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "noise = tf.keras.layers.Input(shape=(num_label_classes, 16))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSkTnwftnbSv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "noised_digit_caps = tf.keras.layers.Add()([digit_caps, noise])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvKJNGQRR6io",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " masked_noised_y = Mask()([noised_digit_caps, y])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGV1lNfJnd6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#masked_noised_y = K.batch_flatten(noised_digit_caps * tf.expand_dims(y, -1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pITXwgvMh-Yh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "manipulate_model = tf.keras.models.Model([x, y, noise], decoder(masked_noised_y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwrLab8mo3Ti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def margin_loss(y_true, y_pred):\n",
        "  \n",
        "    L = y_true * tf.square(tf.maximum(0., 0.9 - y_pred)) + \\\n",
        "        0.5 * (1 - y_true) * tf.square(tf.maximum(0., y_pred - 0.1))\n",
        "\n",
        "    return tf.reduce_mean(tf.reduce_sum(L, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbJtXbNvCaXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log = tf.keras.callbacks.CSVLogger('/log.csv')\n",
        "\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('/weights-{epoch:02d}.h5', monitor='val_capsnet_acc', save_best_only=True, save_weights_only=True, verbose=1)\n",
        "\n",
        "lr_decay = tf.keras.callbacks.LearningRateScheduler(schedule=lambda epoch: 0.001 * (0.9 ** epoch))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-IDqzpyCdeV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compile the model\n",
        "\n",
        "train_model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
        "                loss=[margin_loss, 'mse'],\n",
        "                loss_weights=[1., 0.392],\n",
        "                metrics={'capsnet': 'accuracy'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JObnVNuODuhk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7cfc9d70-b35b-4b16-d98f-023a76b9db96"
      },
      "source": [
        "train_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(32, 32, 32, 3)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (32, 24, 24, 256)    62464       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_conv2d (Conv2D)      (32, 8, 8, 256)      5308672     conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_reshape (Reshape)    (32, 2048, 8)        0           primarycap_conv2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_squash (Lambda)      (32, 2048, 8)        0           primarycap_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims (TensorF [(32, 1, 2048, 8)]   0           primarycap_squash[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_1 (Tenso [(32, 1, 2048, 8, 1) 0           tf_op_layer_ExpandDims[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Tile (TensorFlowOpL [(32, 100, 2048, 8,  0           tf_op_layer_ExpandDims_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Unpack (TensorFlowO [(100, 2048, 8, 1),  0           tf_op_layer_Tile[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2 (Tens [(100, 2048, 16, 1)] 0           tf_op_layer_Unpack[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2_1 (Te [(100, 2048, 16, 1)] 0           tf_op_layer_Unpack[0][1]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2_2 (Te [(100, 2048, 16, 1)] 0           tf_op_layer_Unpack[0][2]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2_3 (Te [(100, 2048, 16, 1)] 0           tf_op_layer_Unpack[0][3]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2_4 (Te [(100, 2048, 16, 1)] 0           tf_op_layer_Unpack[0][4]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2_5 (Te [(100, 2048, 16, 1)] 0           tf_op_layer_Unpack[0][5]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2_6 (Te [(100, 2048, 16, 1)] 0           tf_op_layer_Unpack[0][6]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2_7 (Te [(100, 2048, 16, 1)] 0           tf_op_layer_Unpack[0][7]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2_8 (Te [(100, 2048, 16, 1)] 0           tf_op_layer_Unpack[0][8]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2_9 (Te [(100, 2048, 16, 1)] 0           tf_op_layer_Unpack[0][9]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2_10 (T [(100, 2048, 16, 1)] 0           tf_op_layer_Unpack[0][10]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2_11 (T [(100, 2048, 16, 1)] 0           tf_op_layer_Unpack[0][11]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2_12 (T [(100, 2048, 16, 1)] 0           tf_op_layer_Unpack[0][12]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2_13 (T [(100, 2048, 16, 1)] 0           tf_op_layer_Unpack[0][13]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2_14 (T [(100, 2048, 16, 1)] 0           tf_op_layer_Unpack[0][14]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2_15 (T [(100, 2048, 16, 1)] 0           tf_op_layer_Unpack[0][15]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2_16 (T [(100, 2048, 16, 1)] 0           tf_op_layer_Unpack[0][16]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2_17 (T [(100, 2048, 16, 1)] 0           tf_op_layer_Unpack[0][17]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2_18 (T [(100, 2048, 16, 1)] 0           tf_op_layer_Unpack[0][18]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2_19 (T [(100, 2048, 16, 1)] 0           tf_op_layer_Unpack[0][19]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2_20 (T [(100, 2048, 16, 1)] 0           tf_op_layer_Unpack[0][20]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2_21 (T [(100, 2048, 16, 1)] 0           tf_op_layer_Unpack[0][21]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2_22 (T [(100, 2048, 16, 1)] 0           tf_op_layer_Unpack[0][22]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2_23 (T [(100, 2048, 16, 1)] 0           tf_op_layer_Unpack[0][23]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2_24 (T [(100, 2048, 16, 1)] 0           tf_op_layer_Unpack[0][24]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2_25 (T [(100, 2048, 16, 1)] 0           tf_op_layer_Unpack[0][25]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2_26 (T [(100, 2048, 16, 1)] 0           tf_op_layer_Unpack[0][26]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2_27 (T [(100, 2048, 16, 1)] 0           tf_op_layer_Unpack[0][27]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2_28 (T [(100, 2048, 16, 1)] 0           tf_op_layer_Unpack[0][28]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2_29 (T [(100, 2048, 16, 1)] 0           tf_op_layer_Unpack[0][29]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2_30 (T [(100, 2048, 16, 1)] 0           tf_op_layer_Unpack[0][30]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2_31 (T [(100, 2048, 16, 1)] 0           tf_op_layer_Unpack[0][31]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_packed (TensorFlowO [(32, 100, 2048, 16, 0           tf_op_layer_BatchMatMulV2[0][0]  \n",
            "                                                                 tf_op_layer_BatchMatMulV2_1[0][0]\n",
            "                                                                 tf_op_layer_BatchMatMulV2_2[0][0]\n",
            "                                                                 tf_op_layer_BatchMatMulV2_3[0][0]\n",
            "                                                                 tf_op_layer_BatchMatMulV2_4[0][0]\n",
            "                                                                 tf_op_layer_BatchMatMulV2_5[0][0]\n",
            "                                                                 tf_op_layer_BatchMatMulV2_6[0][0]\n",
            "                                                                 tf_op_layer_BatchMatMulV2_7[0][0]\n",
            "                                                                 tf_op_layer_BatchMatMulV2_8[0][0]\n",
            "                                                                 tf_op_layer_BatchMatMulV2_9[0][0]\n",
            "                                                                 tf_op_layer_BatchMatMulV2_10[0][0\n",
            "                                                                 tf_op_layer_BatchMatMulV2_11[0][0\n",
            "                                                                 tf_op_layer_BatchMatMulV2_12[0][0\n",
            "                                                                 tf_op_layer_BatchMatMulV2_13[0][0\n",
            "                                                                 tf_op_layer_BatchMatMulV2_14[0][0\n",
            "                                                                 tf_op_layer_BatchMatMulV2_15[0][0\n",
            "                                                                 tf_op_layer_BatchMatMulV2_16[0][0\n",
            "                                                                 tf_op_layer_BatchMatMulV2_17[0][0\n",
            "                                                                 tf_op_layer_BatchMatMulV2_18[0][0\n",
            "                                                                 tf_op_layer_BatchMatMulV2_19[0][0\n",
            "                                                                 tf_op_layer_BatchMatMulV2_20[0][0\n",
            "                                                                 tf_op_layer_BatchMatMulV2_21[0][0\n",
            "                                                                 tf_op_layer_BatchMatMulV2_22[0][0\n",
            "                                                                 tf_op_layer_BatchMatMulV2_23[0][0\n",
            "                                                                 tf_op_layer_BatchMatMulV2_24[0][0\n",
            "                                                                 tf_op_layer_BatchMatMulV2_25[0][0\n",
            "                                                                 tf_op_layer_BatchMatMulV2_26[0][0\n",
            "                                                                 tf_op_layer_BatchMatMulV2_27[0][0\n",
            "                                                                 tf_op_layer_BatchMatMulV2_28[0][0\n",
            "                                                                 tf_op_layer_BatchMatMulV2_29[0][0\n",
            "                                                                 tf_op_layer_BatchMatMulV2_30[0][0\n",
            "                                                                 tf_op_layer_BatchMatMulV2_31[0][0\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Squeeze (TensorFlow [(32, 100, 2048, 16) 0           tf_op_layer_packed[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2_32 (T [(32, 100, 1, 16)]   0           tf_op_layer_Squeeze[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Square (TensorFlowO [(32, 100, 1, 16)]   0           tf_op_layer_BatchMatMulV2_32[0][0\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sum (TensorFlowOpLa [(32, 100, 1, 1)]    0           tf_op_layer_Square[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2 (TensorFlowOp [(32, 100, 1, 1)]    0           tf_op_layer_Sum[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_1 (TensorFlow [(32, 100, 1, 1)]    0           tf_op_layer_Sum[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_RealDiv (TensorFlow [(32, 100, 1, 1)]    0           tf_op_layer_Sum[0][0]            \n",
            "                                                                 tf_op_layer_AddV2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sqrt (TensorFlowOpL [(32, 100, 1, 1)]    0           tf_op_layer_AddV2_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_RealDiv_1 (TensorFl [(32, 100, 1, 1)]    0           tf_op_layer_RealDiv[0][0]        \n",
            "                                                                 tf_op_layer_Sqrt[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Mul (TensorFlowOpLa [(32, 100, 1, 16)]   0           tf_op_layer_RealDiv_1[0][0]      \n",
            "                                                                 tf_op_layer_BatchMatMulV2_32[0][0\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2_33 (T [(32, 100, 1, 2048)] 0           tf_op_layer_Mul[0][0]            \n",
            "                                                                 tf_op_layer_Squeeze[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_2 (TensorFlow [(32, 100, 1, 2048)] 0           tf_op_layer_BatchMatMulV2_33[0][0\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Transpose (TensorFl [(32, 2048, 1, 100)] 0           tf_op_layer_AddV2_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Softmax (TensorFlow [(32, 2048, 1, 100)] 0           tf_op_layer_Transpose[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Transpose_1 (Tensor [(32, 100, 1, 2048)] 0           tf_op_layer_Softmax[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2_34 (T [(32, 100, 1, 16)]   0           tf_op_layer_Transpose_1[0][0]    \n",
            "                                                                 tf_op_layer_Squeeze[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Square_1 (TensorFlo [(32, 100, 1, 16)]   0           tf_op_layer_BatchMatMulV2_34[0][0\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sum_1 (TensorFlowOp [(32, 100, 1, 1)]    0           tf_op_layer_Square_1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_3 (TensorFlow [(32, 100, 1, 1)]    0           tf_op_layer_Sum_1[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_4 (TensorFlow [(32, 100, 1, 1)]    0           tf_op_layer_Sum_1[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_RealDiv_2 (TensorFl [(32, 100, 1, 1)]    0           tf_op_layer_Sum_1[0][0]          \n",
            "                                                                 tf_op_layer_AddV2_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sqrt_1 (TensorFlowO [(32, 100, 1, 1)]    0           tf_op_layer_AddV2_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_RealDiv_3 (TensorFl [(32, 100, 1, 1)]    0           tf_op_layer_RealDiv_2[0][0]      \n",
            "                                                                 tf_op_layer_Sqrt_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Mul_1 (TensorFlowOp [(32, 100, 1, 16)]   0           tf_op_layer_RealDiv_3[0][0]      \n",
            "                                                                 tf_op_layer_BatchMatMulV2_34[0][0\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2_35 (T [(32, 100, 1, 2048)] 0           tf_op_layer_Mul_1[0][0]          \n",
            "                                                                 tf_op_layer_Squeeze[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_5 (TensorFlow [(32, 100, 1, 2048)] 0           tf_op_layer_AddV2_2[0][0]        \n",
            "                                                                 tf_op_layer_BatchMatMulV2_35[0][0\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Transpose_2 (Tensor [(32, 2048, 1, 100)] 0           tf_op_layer_AddV2_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Softmax_1 (TensorFl [(32, 2048, 1, 100)] 0           tf_op_layer_Transpose_2[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Transpose_3 (Tensor [(32, 100, 1, 2048)] 0           tf_op_layer_Softmax_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_BatchMatMulV2_36 (T [(32, 100, 1, 16)]   0           tf_op_layer_Transpose_3[0][0]    \n",
            "                                                                 tf_op_layer_Squeeze[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Square_2 (TensorFlo [(32, 100, 1, 16)]   0           tf_op_layer_BatchMatMulV2_36[0][0\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sum_2 (TensorFlowOp [(32, 100, 1, 1)]    0           tf_op_layer_Square_2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_6 (TensorFlow [(32, 100, 1, 1)]    0           tf_op_layer_Sum_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_7 (TensorFlow [(32, 100, 1, 1)]    0           tf_op_layer_Sum_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_RealDiv_4 (TensorFl [(32, 100, 1, 1)]    0           tf_op_layer_Sum_2[0][0]          \n",
            "                                                                 tf_op_layer_AddV2_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sqrt_2 (TensorFlowO [(32, 100, 1, 1)]    0           tf_op_layer_AddV2_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_RealDiv_5 (TensorFl [(32, 100, 1, 1)]    0           tf_op_layer_RealDiv_4[0][0]      \n",
            "                                                                 tf_op_layer_Sqrt_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Mul_2 (TensorFlowOp [(32, 100, 1, 16)]   0           tf_op_layer_RealDiv_5[0][0]      \n",
            "                                                                 tf_op_layer_BatchMatMulV2_36[0][0\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_digitcaps (TensorFl [(32, 100, 16)]      0           tf_op_layer_Mul_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "mask (Mask)                     (32, 1600)           0           tf_op_layer_digitcaps[0][0]      \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "capsnet (Length)                (32, 100)            0           tf_op_layer_digitcaps[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "decoder (Sequential)            multiple             4493824     mask[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 9,864,960\n",
            "Trainable params: 9,864,960\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcesAMpzCgwv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "98a3773c-c11c-40f7-e42e-65e2a348f714"
      },
      "source": [
        "train_model.fit([x_train, y_train], [y_train, x_train], batch_size=32, epochs=50,\n",
        "                validation_data=[[x_test, y_test], [y_test, x_test]], callbacks=[log, checkpoint, lr_decay])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100) for input Tensor(\"input_2:0\", shape=(None, 100), dtype=float32), but it was called on an input with incompatible shape (None, 1).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aLbDxGT3pGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4mqqQctjTDH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.save_weights('/trained_model.h5')\n",
        "print('Trained model saved to \\'%s/trained_model.h5\\'')\n",
        "\n",
        "from utils import plot_log\n",
        "plot_log('/log.csv', show=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSIRkcB2kDYM",
        "colab_type": "text"
      },
      "source": [
        "train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSf-aV1psjKS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred, x_recon = model.predict(x_test, batch_size=100)\n",
        "print('-' * 30 + 'Begin: test' + '-' * 30)\n",
        "print('Test acc:', np.sum(np.argmax(y_pred, 1) == np.argmax(y_test, 1)) / y_test.shape[0])\n",
        "\n",
        "img = combine_images(np.concatenate([x_test[:50], x_recon[:50]]))\n",
        "image = img * 255\n",
        "Image.fromarray(image.astype(np.uint8)).save(args.save_dir + \"/real_and_recon.png\")\n",
        "print()\n",
        "print('Reconstructed images are saved to %s/real_and_recon.png' % args.save_dir)\n",
        "print('-' * 30 + 'End: test' + '-' * 30)\n",
        "plt.imshow(plt.imread(args.save_dir + \"/real_and_recon.png\"))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlpdcBDdo891",
        "colab_type": "text"
      },
      "source": [
        "manipulated model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR-bn0jWjug8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('-' * 30 + 'Begin: manipulate' + '-' * 30)\n",
        "x_test, y_test = data\n",
        "index = np.argmax(y_test, 1) == args.digit\n",
        "number = np.random.randint(low=0, high=sum(index) - 1)\n",
        "x, y = x_test[index][number], y_test[index][number]\n",
        "x, y = np.expand_dims(x, 0), np.expand_dims(y, 0)\n",
        "noise = np.zeros([1, 10, 16])\n",
        "x_recons = []\n",
        "for dim in range(16):\n",
        "    for r in [-0.25, -0.2, -0.15, -0.1, -0.05, 0, 0.05, 0.1, 0.15, 0.2, 0.25]:\n",
        "        tmp = np.copy(noise)\n",
        "        tmp[:, :, dim] = r\n",
        "        x_recon = model.predict([x, y, tmp])\n",
        "        x_recons.append(x_recon)\n",
        "\n",
        "x_recons = np.concatenate(x_recons)\n",
        "\n",
        "img = combine_images(x_recons, height=16)\n",
        "image = img * 255\n",
        "Image.fromarray(image.astype(np.uint8)).save(args.save_dir + '/manipulate-%d.png' % args.digit)\n",
        "print('manipulated result saved to %s/manipulate-%d.png' % (args.save_dir, args.digit))\n",
        "print('-' * 30 + 'End: manipulate' + '-' * 30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NI-7vt-7pAJq",
        "colab_type": "text"
      },
      "source": [
        "test model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPXuzS4lkKLu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred, x_recon = eval_model.predict(x_test, batch_size=100)\n",
        "print('-' * 30 + 'Begin: test' + '-' * 30)\n",
        "print('Test acc:', np.sum(np.argmax(y_pred, 1) == np.argmax(y_test, 1)) / y_test.shape[0])\n",
        "\n",
        "img = combine_images(np.concatenate([x_test[:50], x_recon[:50]]))\n",
        "image = img * 255\n",
        "Image.fromarray(image.astype(np.uint8)).save(args.save_dir + \"/real_and_recon.png\")\n",
        "print()\n",
        "print('Reconstructed images are saved to %s/real_and_recon.png' % args.save_dir)\n",
        "print('-' * 30 + 'End: test' + '-' * 30)\n",
        "plt.imshow(plt.imread(args.save_dir + \"/real_and_recon.png\"))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}